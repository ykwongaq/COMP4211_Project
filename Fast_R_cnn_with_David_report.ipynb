{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hT42F05lCKtv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from sklearn.model_selection import KFold\n",
    "# from tqdm.auto import tqdm\n",
    "from scipy import ndimage\n",
    "import pickle\n",
    "import logging\n",
    "import torchvision.models as models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WUXmPLACKtv",
    "outputId": "33dcec80-492c-4485-c390-3e89a0e28304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "assert os.environ['COLAB_GPU'], 'Make sure to select GPU from Edit > Notebook settings > Hardware accelerator'\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9mZJS2FsAGE"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qsyFTu4rCP3G"
   },
   "outputs": [],
   "source": [
    "!rm -f data\n",
    "!ln -s '/content/drive/MyDrive/proj2_data' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4CcEo-6b_pt"
   },
   "source": [
    "##some utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i5Rf9j6qkVU"
   },
   "outputs": [],
   "source": [
    "def collate_fn1(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def imshow(img, gt_box, turb_type,pred_box=None):\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    def draw_box(box, turb_type):\n",
    "        x, y, w, h = box\n",
    "        if x == 0:\n",
    "            x = 1\n",
    "        if y == 0:\n",
    "            y = 1\n",
    "        if turb_type=='turbulence':\n",
    "          color='red'\n",
    "        else:\n",
    "          color='green'\n",
    "        plt.gca().add_patch(\n",
    "            plt.Rectangle((x, y), w-x, h-y,\n",
    "                          fill=False, edgecolor=color, linewidth=2, alpha=0.5)\n",
    "        )\n",
    "    for i in range(len(box)):\n",
    "      draw_box(box[i],turb_type[i])\n",
    "    if pred_box is not None:\n",
    "        draw_box(pred_box, 'blue')\n",
    "    plt.plot()\n",
    "\n",
    "def to_2d_tensor(inp):\n",
    "    inp = torch.Tensor(inp)\n",
    "    if len(inp.size()) < 2:\n",
    "        inp = inp.unsqueeze(0)\n",
    "    return inp\n",
    "\n",
    "def box_transform_inv(boxes, im_sizes):\n",
    "    # box in (x, y, w, h) format\n",
    "    boxes = to_2d_tensor(boxes)\n",
    "    im_sizes = to_2d_tensor(im_sizes)\n",
    "    boxes[:, 0] = (boxes[:, 0] + 1) / 2 * im_sizes[:, 0]\n",
    "    boxes[:, 1] = (boxes[:, 1] + 1) / 2 * im_sizes[:, 1]\n",
    "    boxes[:, 2] = boxes[:, 2] / 2 * im_sizes[:, 0]\n",
    "    boxes[:, 3] = boxes[:, 3] / 2 * im_sizes[:, 1]\n",
    "    return boxes\n",
    "\n",
    "def box_transform(boxes, im_sizes):\n",
    "    # box in (x, y, w, h) format\n",
    "    boxes = to_2d_tensor(boxes)\n",
    "    im_sizes = to_2d_tensor(im_sizes)\n",
    "    boxes[:, 0] = 2 * boxes[:, 0] / im_sizes[:, 0] - 1\n",
    "    boxes[:, 1] = 2 * boxes[:, 1] / im_sizes[:, 1] - 1\n",
    "    boxes[:, 2] = 2 * boxes[:, 2] / im_sizes[:, 0]\n",
    "    boxes[:, 3] = 2 * boxes[:, 3] / im_sizes[:, 1]\n",
    "    return boxes\n",
    "\n",
    "def xywh_to_x1y1x2y2(boxes):\n",
    "    boxes = to_2d_tensor(boxes)\n",
    "    boxes[:, 2] += boxes[:, 0] - 1\n",
    "    boxes[:, 3] += boxes[:, 1] - 1\n",
    "    return boxes\n",
    "\n",
    "def x1y1x2y2_to_xywh(boxes):\n",
    "    boxes = to_2d_tensor(boxes)\n",
    "    boxes[:, 2] -= boxes[:, 0] - 1\n",
    "    boxes[:, 3] -= boxes[:, 1] - 1\n",
    "    return boxes\n",
    "\n",
    "def compute_IoU(boxes1, boxes2):\n",
    "    boxes1 = to_2d_tensor(boxes1)\n",
    "    boxes1 = xywh_to_x1y1x2y2(boxes1)\n",
    "    boxes2 = to_2d_tensor(boxes2)\n",
    "    boxes2 = xywh_to_x1y1x2y2(boxes2)\n",
    "    \n",
    "    intersec = boxes1.clone()\n",
    "    intersec[:, 0] = torch.max(boxes1[:, 0], boxes2[:, 0])\n",
    "    intersec[:, 1] = torch.max(boxes1[:, 1], boxes2[:, 1])\n",
    "    intersec[:, 2] = torch.min(boxes1[:, 2], boxes2[:, 2])\n",
    "    intersec[:, 3] = torch.min(boxes1[:, 3], boxes2[:, 3])\n",
    "    \n",
    "    def compute_area(boxes):\n",
    "        # in (x1, y1, x2, y2) format\n",
    "        dx = boxes[:, 2] - boxes[:, 0]\n",
    "        dx[dx < 0] = 0\n",
    "        dy = boxes[:, 3] - boxes[:, 1]\n",
    "        dy[dy < 0] = 0\n",
    "        return dx * dy\n",
    "    \n",
    "    a1 = compute_area(boxes1)\n",
    "    a2 = compute_area(boxes2)\n",
    "    ia = compute_area(intersec)\n",
    "    assert((a1 + a2 - ia <= 0).sum() == 0)\n",
    "    \n",
    "    return ia / (a1 + a2 - ia)    \n",
    "\n",
    "def compute_acc(preds, targets, theta=0.75):\n",
    "    IoU = compute_IoU(preds.clone(), targets.clone())\n",
    "    corr = (IoU >= theta).sum()\n",
    "    return corr.item() / preds.size(0)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt\n",
    "        \n",
    "def box_to_mask(box, im_size):\n",
    "    mask = np.zeros(im_size)\n",
    "    co = xywh_to_x1y1x2y2(box)[0].type(torch.int64)\n",
    "    mask[co[0]: co[2], co[1]: co[3]] = 1\n",
    "    return Image.fromarray(np.uint8(mask*255).T)\n",
    "\n",
    "def mask_to_box(mask):\n",
    "    mask = torch.nonzero(mask[0, :, :].T != 0, as_tuple=False)\n",
    "    x1, y1 = torch.min(mask, dim=0).values\n",
    "    x2, y2 = torch.max(mask, dim=0).values\n",
    "    return x1y1x2y2_to_xywh([x1, y1, x2, y2])[0]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xW3sOHSayqQb"
   },
   "source": [
    "### Utilities for Herarchical Grouping Algorithm\n",
    "\n",
    "- `extractextractImgbyRoI(img, Coords)`:\n",
    "\n",
    "  Crop the image base on the given Coordinates\n",
    "\n",
    "- `constructNeighbourGrid()`\n",
    "\n",
    "  Construct the Neighbour Grid. In this project, the neighbour grid is a 100-by-100 matrix\n",
    "\n",
    "- `initCoord()`\n",
    "\n",
    "  Divide the image into 10*10 regions. It resturns the coordinates `(x_min, y_min, x_max, y_max)` of those regions\n",
    "\n",
    "- `initRegions()`\n",
    "  \n",
    "  Initialize the output RoIs. It return a set that contain the ID of initial 100 regions. Set is used so that element can join the set easily\n",
    "\n",
    "- `regionsToCoord(Coords, Regions)`\n",
    "\n",
    "  Base on the given regions ID `Regions`, return the corresponding coordinates `(x_min, y_min, x_max, y_max)` of that regions\n",
    "\n",
    "- `getHist(img)`\n",
    "\n",
    "  Gernerate the histrogram for the given image `img`.\n",
    "\n",
    "- `sim(region1, region2)`\n",
    "\n",
    "  Calculate the similarity of two given regions of image.\n",
    "\n",
    "- `findNeighbour(regions, size)`\n",
    "\n",
    "  Base on the given regions ID, find it's neighbour. It return the ID of it's neighbour regions. In this project, `size` is 10\n",
    "\n",
    "- `tuple2list(input)`\n",
    "\n",
    "  Convert the given list of tuple and integers to a list without tuple. The input list usually contain a mixture of tuple and integer. This fucntion extract the element in the tuple to form a list together with other integers\n",
    "\n",
    "- `removeEnclosedRegion(regions, newR)`\n",
    "\n",
    "  Remove the region in `regions` that already covered by `newR`. In other word, it remove all the subset of `newR`\n",
    "\n",
    "  If `regions = [(1, 2), (3, 4)]` and `newR = (1, 2, 5)`, the result will be `[(1, 2, 5), (3, 4)]`\n",
    "\n",
    "\n",
    "- `cropRect(ROIs, regions)`\n",
    "\n",
    "    Since the regions after merging may not be a rectangle, this function will crop the smallest rectangle that contain the regions. The output is the coordinate of those the smalles rectangles\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6ugc6omy_9H"
   },
   "outputs": [],
   "source": [
    "#### ROI_PROPOSAL_ALGORITHM\n",
    "def extractImgbyRoI(img, Coords):\n",
    "  (x_min, y_min, x_max, y_max) = Coords[0]\n",
    "  result = img[:, y_min:y_max, x_min:x_max]\n",
    "  for i in range(1, len(Coords)):\n",
    "    (x_min, y_min, x_max, y_max) = Coords[i]\n",
    "    result = np.concatenate((result, img[:, y_min:y_max, x_min:x_max]), axis=2)\n",
    "  return np.array(result)\n",
    "\n",
    "def myImgShow(img):\n",
    "  img = img.transpose((1, 2, 0))/255\n",
    "  #img = img.numpy().transpose((1, 2, 0))/255\n",
    "  plt.imshow(img)\n",
    "\n",
    "def constructNeighbourGrid():\n",
    "  size = 10\n",
    "  neighbourGrid = []\n",
    " \n",
    "  for i in range(size):\n",
    "    for j in range(size):\n",
    "      background = np.zeros((10, 10))\n",
    "      #background[i][j] = 1\n",
    "      # Dilation\n",
    "      if i-1 >= 0: background[i-1][j] = 1\n",
    "      if i+1 < size: background[i+1][j] = 1\n",
    "      if j-1 >= 0: background[i][j-1] = 1\n",
    "      if j+1 < size: background[i][j+1] = 1\n",
    "\n",
    "      background = background.flatten()\n",
    "      neighbourGrid.append(background == 1)\n",
    "\n",
    "  return np.array(neighbourGrid)\n",
    "\n",
    "def initCoord(img, size):\n",
    "  _, h, w = img.shape\n",
    "  sub_h, sub_w = math.floor(h/size), math.floor(w/size)\n",
    "  RoIs = np.array([[[j*sub_w, i*sub_h, (j+1)*sub_w-1, (i+1)*sub_h-1] for j in range(size)] for i in range(size)])\n",
    "  RoIs = RoIs.reshape(size*size, 4)\n",
    "  return RoIs\n",
    "    \n",
    "\n",
    "def initRegions(size):\n",
    "  return set([(i) for i in range(size)])\n",
    "\n",
    "\n",
    "def regionsToCoord(Coords, regions):\n",
    "  regions_list = tuple2list(regions)\n",
    "  res = Coords[regions_list[0]].reshape(1, 4)\n",
    "  for i in range(1, len(regions_list)):\n",
    "    res = np.concatenate((res, Coords[regions_list[i]].reshape((1, 4))))\n",
    "  return res\n",
    "\n",
    "\n",
    "def regionsToCoord_test(Coords, regions):\n",
    "  print(regions)\n",
    "  regions_list = tuple2list(regions)\n",
    "  print(regions_list[0])\n",
    "  print(Coords[regions_list[0]].reshape(1, 4))\n",
    "  res = Coords[regions_list[0]].reshape(1, 4)\n",
    "  for i in range(1, len(regions_list)):\n",
    "    res = np.concatenate((res, Coords[regions_list[i]].reshape((1, 4))))\n",
    "  return res\n",
    "\n",
    "\n",
    "def getHist(img):\n",
    "  D, _, _ = img.shape\n",
    "  histogram = []\n",
    "  for channel_idx in range(D):\n",
    "    h, _ = np.histogram(img[channel_idx, :, :], bins=25)\n",
    "    histogram = histogram + list(h)\n",
    "  histogram = np.array(histogram/np.linalg.norm(histogram, 1))\n",
    "  return histogram\n",
    "\n",
    "def sim(region1, region2):\n",
    "  histogram1 = getHist(region1)\n",
    "  histogram2 = getHist(region2)\n",
    "\n",
    "  sim = np.vstack((histogram1, histogram2))\n",
    "  sim = np.amin(sim, 0)\n",
    "  sim = sim.sum()\n",
    "\n",
    "  return sim\n",
    "\n",
    "def findNeighbour(regions, size):\n",
    "  neighbourGrid = np.zeros((size*size, 1))\n",
    "  neighbourGrid[tuple2list(regions)] = 1\n",
    "  neighbourGrid = neighbourGrid.reshape((size, size))\n",
    "  neighbourGrid = ndimage.binary_dilation(neighbourGrid).astype(neighbourGrid.dtype)\n",
    "  neighbourGrid = neighbourGrid.reshape((size*size, 1))\n",
    "  neighbourGrid[tuple2list(regions)] = 0\n",
    "  return np.where(neighbourGrid == 1)[0]\n",
    "\n",
    "def tuple2list(input):\n",
    "  if type(input) == int:\n",
    "    return [input]\n",
    "  res = []\n",
    "  for element in input:\n",
    "    if type(element) == tuple:\n",
    "      res = res + list(element)\n",
    "    else:\n",
    "      res.append(element)\n",
    "  return res\n",
    "\n",
    "def removeEnclosedRegion(regions, newR):\n",
    "  redundance = set()\n",
    "  for t in regions:\n",
    "    if set(t).issubset(newR):\n",
    "      redundance.add(t)\n",
    "\n",
    "  regions.symmetric_difference_update(redundance)\n",
    "  return regions\n",
    "\n",
    "def cropRect(RoIs, regions):\n",
    "  res = RoIs\n",
    "  for region in regions:\n",
    "    coords = regionsToCoord(RoIs, region)\n",
    "\n",
    "    coord_max = np.amax(coords, axis=0)\n",
    "    coord_min = np.amin(coords, axis=0)\n",
    "\n",
    "    vector = [coord_min[0], coord_min[1], coord_max[2], coord_max[3]]\n",
    "    res = np.vstack((res, vector))\n",
    "\n",
    "  return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierachical Grouping Algorithm\n",
    "\n",
    "- `genRoIsperImg(im, size)`\n",
    "\n",
    "`im`: the input image\n",
    "`size`: how many regions to be devided for initialization. If `size` is 10, then 10\\*10 reisons will be initialized\n",
    "\n",
    "Procedures:\n",
    "1. Regions initialization using `initCoord` and `initRegions`. In this project, 10\\*10 regions are initialized\n",
    "2. Generate the similarity grid for each nearby regions. similarity grid is a 100\\*100 matrix for this project. For example, s(r_1, r_2) store the value of similarity of r_1 and r_2. If r_1 and r_2 are not neighbour, the value will be `np.NaN`\n",
    "3. Merge the regions with highest similarity and calculate the similarities again\n",
    "4. Continue until the image left with one region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwP1M4Dh7UZM"
   },
   "outputs": [],
   "source": [
    "def genRoIsperImg(im, size): \n",
    "  RoIs = initCoord(im, size)\n",
    "  regions = initRegions(size*size)\n",
    "\n",
    "  neighbourGrid = constructNeighbourGrid()\n",
    "\n",
    "  simGrid = set()\n",
    "  for i in range(size*size):\n",
    "    for j in range(i, size*size):\n",
    "      if neighbourGrid[i][j]:\n",
    "        img1 = extractImgbyRoI(im, regionsToCoord(RoIs, [i]))\n",
    "        img2 = extractImgbyRoI(im, regionsToCoord(RoIs, [j]))\n",
    "        simGrid.add((i, j, sim(img1, img2)))\n",
    "\n",
    "  regions_merged = set()\n",
    "  current_merged_regions = set()\n",
    "  i = 0\n",
    "  while len(simGrid) > 0:\n",
    "  #for i in range(20):\n",
    "    # print('itr#:', i, \" with size= \", len(simGrid))\n",
    "    i = i+1\n",
    "    region1, region2, _ = max(simGrid, key=lambda x:x[2])\n",
    "    #print(\"region1 = \", region1)\n",
    "    #print(\"region2 = \", region2)\n",
    "    newRegion = set()\n",
    "    newRegion.update(tuple2list(region1))\n",
    "    newRegion.update(tuple2list(region2))\n",
    "    regions_merged.add(tuple(newRegion))\n",
    "    current_merged_regions = removeEnclosedRegion(current_merged_regions, tuple(newRegion))\n",
    "    current_merged_regions.add(tuple(newRegion))\n",
    "    removeList = list(filter(lambda x: x[0] == region1 or x[1] == region1, simGrid))\n",
    "    #print(\"remove one = \", removeList)\n",
    "    c1 = len(removeList)\n",
    "    simGrid.difference_update(removeList)\n",
    "    removeList = list(filter(lambda x: x[0] == region2 or x[1] == region2, simGrid))\n",
    "    #print(\"remove two = \", removeList)\n",
    "    c1 = c1 + len(removeList)\n",
    "    #print(\"no of removal = \", c1)\n",
    "    simGrid.difference_update(removeList)\n",
    "\n",
    "    neighbourRegions = findNeighbour(newRegion, 10)\n",
    "    #print(\"neigbour regions = \", neighbourRegions)\n",
    "    for j in range(len(neighbourRegions)):\n",
    "      neighbourRegion = neighbourRegions[j]\n",
    "      #print(\"==== current neibh = \", neighbourRegion)\n",
    "      counted = False\n",
    "      for region in filter(lambda x: neighbourRegion in x, current_merged_regions):\n",
    "        #print(\"region = \", region)\n",
    "        counted = True\n",
    "        img1 = extractImgbyRoI(im, regionsToCoord(RoIs, newRegion))\n",
    "        img2 = extractImgbyRoI(im, regionsToCoord(RoIs, region))\n",
    "        #print(\"add: \", (tuple(newRegion), region, sim(img1, img2)))\n",
    "        simGrid.add((tuple(newRegion), region, sim(img1, img2)))\n",
    "\n",
    "      if counted:\n",
    "        #print(neighbourRegion, ' is counted')\n",
    "        continue\n",
    "\n",
    "      for region in filter(lambda x:x==neighbourRegion, regions):\n",
    "        #print(\"single region = \", region)\n",
    "        img1 = extractImgbyRoI(im, regionsToCoord(RoIs, newRegion))\n",
    "        img2 = extractImgbyRoI(im, regionsToCoord(RoIs, [region]))\n",
    "        #print(\"add: \", (tuple(newRegion), region, sim(img1, img2)))\n",
    "        simGrid.add((tuple(newRegion), region, sim(img1, img2)))\n",
    "\n",
    "    if len(simGrid) <= 0:\n",
    "      break\n",
    "  \n",
    "  res = cropRect(RoIs, regions_merged)\n",
    "  res = set([tuple(ele) for ele in res])\n",
    "  res = np.array(list(res))\n",
    "  # print(\"finish\")\n",
    "  return res\n",
    "    #print(regions_merged)\n",
    "    #print(len(simGrid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kfhg8gxbb5_X"
   },
   "source": [
    "## define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0G9yV9Xqw7l"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, datatype='train', transform=None):\n",
    "        with open('data/bbox_'+datatype+'.csv') as f:\n",
    "            id_to_box = dict()\n",
    "            id_to_path = dict()\n",
    "            id_to_turb= dict()\n",
    "            last_name='none'\n",
    "            idx=-1\n",
    "            for line in f.read().splitlines():\n",
    "                filename, wid, hei, turb, *box = line.split(',') # get all variable\n",
    "                if turb =='severe turbulence':\n",
    "                  turb_no=2\n",
    "                else:\n",
    "                  turb_no=1\n",
    "                if filename == 'filename': # skip the title\n",
    "                  continue\n",
    "\n",
    "                if filename==last_name:\n",
    "                  id_to_box[idx].append(list(map(float, box)))\n",
    "                  id_to_turb[idx].append(turb_no)\n",
    "                  \n",
    "                else:\n",
    "                  idx=idx+1\n",
    "                  id_to_path[idx]=filename\n",
    "                  id_to_box[idx]=[list(map(float, box))]\n",
    "                  id_to_turb[idx]=[turb_no]\n",
    "                  last_name=filename\n",
    "\n",
    "            self.imgs = [(os.path.join('data/'+datatype, id_to_path[i]), id_to_box[i],id_to_turb[i])\n",
    "                     for i in range(len(id_to_path))]\n",
    "\n",
    "            #transform data\n",
    "            self.target_transform = transforms.Compose([\n",
    "                transforms.Resize((840, 840)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            self.transform = transforms.Compose([\n",
    "                self.target_transform,\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            if transform is not None:\n",
    "                self.transform = transforms.Compose([\n",
    "                    transform,\n",
    "                    self.transform\n",
    "                ])\n",
    "                self.target_transform = transforms.Compose([\n",
    "                    transform,\n",
    "                    self.target_transform\n",
    "                ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "      \n",
    "\n",
    "      self.data = []\n",
    "      img_count = 1\n",
    "      for img in self.imgs:\n",
    "        # if img_count == 5:\n",
    "        #   break\n",
    "        print(\"processing image#: \", img_count)\n",
    "        img_count = img_count+1\n",
    "        path, box, turb = img\n",
    "        im = (np.load(path))/292*255\n",
    "        im=np.transpose(im,(1, 2, 0))\n",
    "        im=np.uint8(im)\n",
    "        boxes = np.array(box, dtype='int32')\n",
    "        seed = np.random.randint(2147483647)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        PIL = transforms.ToPILImage()(im).convert('RGB')#if you want to output 4 dimension data, change to .convert('RGBA'). While you will not able to do transforms.Normalize()\n",
    "        im = self.transform(PIL)\n",
    "\n",
    "        v = genRoIsperImg(im, 10)\n",
    "\n",
    "\n",
    "        proposed_roi_lable = []\n",
    "        for i in v:\n",
    "          IoU_list = []\n",
    "          for gt_box in box:\n",
    "            IoU = compute_IoU(i, gt_box)\n",
    "            IoU_list.append(IoU)\n",
    "          most_likely_gt_box_iou_score = max(IoU_list)\n",
    "          most_likely_gt_index = IoU_list.index(most_likely_gt_box_iou_score)\n",
    "          gt_box_coord = box[most_likely_gt_index]\n",
    "          if most_likely_gt_box_iou_score > 0:\n",
    "            gt_box_class = turb[most_likely_gt_index]\n",
    "          else:\n",
    "            gt_box_class = 0\n",
    "          \n",
    "          gt_box_coord_xywh = np.array([gt_box_coord[0],gt_box_coord[1],gt_box_coord[2]-gt_box_coord[0],gt_box_coord[3]-gt_box_coord[1]])\n",
    "\n",
    "\n",
    "\n",
    "          roi_dict = {\n",
    "              \"gt_box_iou_score\": most_likely_gt_box_iou_score,\n",
    "              \"gt_index\": most_likely_gt_index,\n",
    "              \"gt_box_coord\": gt_box_coord,\n",
    "              \"gt_box_coord_xywh\": gt_box_coord_xywh,\n",
    "              \"gt_box_class\": gt_box_class\n",
    "          }\n",
    "\n",
    "          proposed_roi_lable.append([i,roi_dict])\n",
    "\n",
    "        self.data.append([im, box, turb, proposed_roi_lable])\n",
    "\n",
    "          # print(most_likely_gt_box_iou_score, most_likely_gt_index, gt_box_coord, gt_box_class)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bv3EYgjbhp1M"
   },
   "outputs": [],
   "source": [
    "train=MyDataset(datatype='train', transform=None)\n",
    "train.prepare_data()\n",
    "torch.save(train,'/content/data/train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRQ-NF9a6Jw2"
   },
   "outputs": [],
   "source": [
    "train=MyDataset(datatype='val', transform=None)\n",
    "train.prepare_data()\n",
    "torch.save(train,'/content/data/val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLKJztNr6L24"
   },
   "outputs": [],
   "source": [
    "train=MyDataset(datatype='test', transform=None)\n",
    "train.prepare_data()\n",
    "torch.save(train,'/content/data/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atiaPmL4rZwB"
   },
   "outputs": [],
   "source": [
    "train = torch.load('/content/data/train.pt')\n",
    "val = torch.load('/content/data/val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WetxELBGvlf"
   },
   "outputs": [],
   "source": [
    "test = torch.load('/content/data/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LL4M4GSOups1"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train,batch_size=2,shuffle=False,collate_fn=collate_fn1)\n",
    "val_dataloader = torch.utils.data.DataLoader(val,batch_size=2,shuffle=False,collate_fn=collate_fn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHXiFcpbG230"
   },
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test,batch_size=2,shuffle=False,collate_fn=collate_fn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOUYd1voDl2A"
   },
   "source": [
    "## minibatch sampling\n",
    "\n",
    "Mini_batch_sampling follow the procedures mentioned in the paper.\n",
    "\n",
    "Procedures:\n",
    "1. First determine the rois that have the IoU score above or equal to 0.5 and mark them as positive\n",
    "2. Determine the rois that have the IoU score above or equal to 0.1 and below 0.5 and mark them as negative\n",
    "3. If portion = 0.5, then select 0.5 of the total number of positive rois as output\n",
    "4. Then add the negative rois to make sure the number of output rois are the same as the give size `size`\n",
    "5. Variable `new` determine how to select positive rois. If `True`, it will select the portion of rois with max. iou scoure. If `False`, it will select the rois with min. iou score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rzQuuoZ0dz1"
   },
   "outputs": [],
   "source": [
    "# False -> Use old sampling method\n",
    "# True -> Use new sampling method\n",
    "def mini_batch_sampling(rois, size, portion, new=False):\n",
    "  res = []\n",
    "  if new:\n",
    "    for roi in rois:\n",
    "      # Extract ious scoure from dictionary\n",
    "      roi = np.array(roi, dtype=object)\n",
    "      dictionaries = roi[:, 1]\n",
    "      ious = list(map(lambda x:x.get('gt_box_iou_score').item(), dictionaries))\n",
    "      ious = np.array(ious)\n",
    "\n",
    "      # Find the locaiton grid for postive label and negative label\n",
    "      posLocation = (ious >= 0.5).astype(int)\n",
    "      negLocation = ((ious >= 0.1)*(ious < 0.5)).astype(int)\n",
    "\n",
    "      # Calculate the \n",
    "      posCount = np.sum(posLocation)\n",
    "      no_of_pos_needed = math.floor(posCount*protion) if posCount*protion <= size else size\n",
    "      no_of_neg_needed = size - no_of_pos_needed\n",
    "\n",
    "      outputIdx = []\n",
    "\n",
    "      # Extract pos index\n",
    "      if no_of_pos_needed > 0:\n",
    "        temp_ious = ious.copy()\n",
    "        temp_ious[(1-posLocation).astype(bool)] = -1\n",
    "        pos_idx = np.argpartition(temp_ious, -no_of_pos_needed)[-no_of_pos_needed:]\n",
    "        #print(pos_idx)\n",
    "        outputIdx = outputIdx + list(pos_idx)\n",
    "      \n",
    "      if no_of_neg_needed > 0:\n",
    "        ious[(1-negLocation).astype(bool)] = -1\n",
    "        neg_idx = np.argpartition(ious, -no_of_neg_needed)[-no_of_neg_needed:]\n",
    "        outputIdx = outputIdx + list(neg_idx)\n",
    "\n",
    "      res.append(outputIdx)\n",
    "  else:\n",
    "    for roi in rois:\n",
    "      # Extract ious scoure from dictionary\n",
    "      roi = np.array(roi, dtype=object)\n",
    "      dictionaries = roi[:, 1]\n",
    "      ious = list(map(lambda x:x.get('gt_box_iou_score').item(), dictionaries))\n",
    "      ious = np.array(ious)\n",
    "\n",
    "      #print(ious)\n",
    "\n",
    "      # Find the locaiton grid for postive label and negative label\n",
    "      posLocation = (ious >= 0.5).astype(int)\n",
    "      negLocation = ((ious >= 0.1)*(ious < 0.5)).astype(int)\n",
    "\n",
    "      # Calculate the \n",
    "      posCount = np.sum(posLocation)\n",
    "      #print(\"cosCount = \", posCount)\n",
    "      no_of_pos_needed = math.floor(posCount*portion) if posCount*portion <= size else size\n",
    "      no_of_neg_needed = size - no_of_pos_needed\n",
    "\n",
    "      #print(\"no_of_pos_needed = \", no_of_pos_needed)\n",
    "      #print(\"no_of_neg_needed = \", no_of_neg_needed)\n",
    "      \n",
    "      outputIdx = []\n",
    "\n",
    "      # Extract pos index\n",
    "      pos_idx = np.where(posLocation == 1)[0]\n",
    "      #print(pos_idx)\n",
    "      outputIdx = outputIdx + list(pos_idx[0:no_of_pos_needed])\n",
    "\n",
    "      #print(\"positive output = \", len(outputIdx))\n",
    "      #print(outputIdx)\n",
    "      if no_of_neg_needed > 0:\n",
    "        ious[(1-negLocation).astype(bool)] = -1\n",
    "\n",
    "        #print(len(ious))\n",
    "        #print(ious)    \n",
    "        #print(np.where(ious == np.max(ious)))\n",
    "        neg_idx = np.argpartition(ious, -no_of_neg_needed)[-no_of_neg_needed:]\n",
    "        outputIdx = outputIdx + list(neg_idx)\n",
    "\n",
    "      #print(\"negative and positive output = \", len(outputIdx))\n",
    "      res.append(outputIdx)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gFbpRdMG6Sw"
   },
   "source": [
    "## Fast R CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0dPy2ACHi5g"
   },
   "outputs": [],
   "source": [
    "def _smooth_l1_loss(x, t, in_weight, sigma):\n",
    "    sigma2 = sigma ** 2\n",
    "    diff = in_weight * (x - t)\n",
    "    abs_diff = diff.abs()\n",
    "    flag = (abs_diff.data < (1. / sigma2)).float()\n",
    "    y = (flag * (sigma2 / 2.) * (diff ** 2) +\n",
    "         (1 - flag) * (abs_diff - 0.5 / sigma2))\n",
    "    return y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hD4iYhsHpJO"
   },
   "outputs": [],
   "source": [
    "def fast_rcnn_loc_loss(pred_loc, gt_loc, gt_label, sigma):\n",
    "    in_weight = torch.zeros(gt_loc.shape).cuda()\n",
    "    # Localization loss is calculated only for positive rois.\n",
    "    # NOTE:  unlike origin implementation, \n",
    "    # we don't need inside_weight and outside_weight, they can calculate by gt_label\n",
    "    in_weight[(gt_label > 0).view(-1, 1).expand_as(in_weight).cuda()] = 1\n",
    "    loc_loss = _smooth_l1_loss(pred_loc, gt_loc, in_weight.detach(), sigma)\n",
    "    # Normalize by total number of negtive and positive rois.\n",
    "    loc_loss /= ((gt_label >= 0).sum().float()) # ignore gt_label==-1 for rpn_loss\n",
    "    return loc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyR04ad_G-C_"
   },
   "outputs": [],
   "source": [
    "def normal_init(m, mean, stddev, truncated=False):\n",
    "    \"\"\"\n",
    "    weight initalizer: truncated normal and random normal.\n",
    "    \"\"\"\n",
    "    # x is a parameter\n",
    "    if truncated:\n",
    "        m.weight.data.normal_().fmod_(2).mul_(stddev).add_(mean)  # not a perfect approximation\n",
    "    else:\n",
    "        m.weight.data.normal_(mean, stddev)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_y4YK1UHCjG"
   },
   "outputs": [],
   "source": [
    "class Fast_R_cnn(nn.Module):\n",
    "  def __init__(self, roi_size, scaling_factor, rois_per_image,pretrained=True):\n",
    "    super(Fast_R_cnn, self).__init__()\n",
    "    self.roi_size = roi_size\n",
    "    self.scaling_factor = scaling_factor\n",
    "    alexnet = models.alexnet(pretrained=pretrained)\n",
    "    #structure of alexnet could be modified if performance is bad\n",
    "    self.alexnet = nn.Sequential(*list(alexnet.children())[:-2])\n",
    "    self.alexnet[0][12]=nn.Identity() \n",
    "\n",
    "    self.ROI_pooling_layer = torchvision.ops.roi_pool\n",
    "    self.rois_per_image = rois_per_image\n",
    "\n",
    "\n",
    "    ## FCs to produced ROI feature vectors\n",
    "    self.ROI_head = nn.Sequential(\n",
    "      nn.Linear(in_features=43264, out_features=21632, bias=True),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Dropout(p=0.5, inplace=False),\n",
    "      nn.Linear(in_features=21632, out_features=10816, bias=True),\n",
    "      nn.ReLU(inplace=True),\n",
    "      # nn.Dropout(p=0.5, inplace=False),\n",
    "      nn.Linear(in_features=10816, out_features=3000, bias=True)\n",
    "      # nn.ReLU(inplace=True),\n",
    "      # nn.Dropout(p=0.5, inplace=False),\n",
    "      # nn.Linear(in_features=5000, out_features=5000, bias=True),\n",
    "      # nn.ReLU(inplace=True),\n",
    "      # nn.Linear(in_features=5000, out_features=3000, bias=True)\n",
    "    )\n",
    "\n",
    "    n_class = 2\n",
    "    ## FCs for softmax \n",
    "    self.classficiation_label = nn.Sequential(\n",
    "      nn.Linear(3000, 3), #Because 3 classes\n",
    "      nn.Softmax()\n",
    "    )\n",
    "\n",
    "    ## FCs for bbox regressor \n",
    "    self.fc_before_regressor = nn.Sequential(\n",
    "      nn.Linear(3000, 4),\n",
    "    )\n",
    "\n",
    "    ## input using pool5 fectures and output for weigths for the bounding box calculation\n",
    "    self.regressor = nn.Sequential(\n",
    "      nn.Linear(3000, 4),\n",
    "    )\n",
    "\n",
    "    normal_init(self.fc_before_regressor[0], 0, 0.001)\n",
    "    normal_init(self.regressor[0], 0, 0.001)\n",
    "    normal_init(self.classficiation_label[0], 0, 0.01)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, images_data, roi_list):\n",
    "\n",
    "    conv_feature_map = self.alexnet(images_data)\n",
    "    # print(conv_feature_map.shape)\n",
    "\n",
    "    proposed_roi = roi_list\n",
    "\n",
    "    roi_pooling_result = self.ROI_pooling_layer(input = conv_feature_map, boxes= proposed_roi, output_size = self.roi_size, spatial_scale= self.scaling_factor)\n",
    "\n",
    "    # print(roi_pooling_result.shape)\n",
    "\n",
    "\n",
    "    roi = torch.reshape(roi_pooling_result, (2*self.rois_per_image,43264))\n",
    "\n",
    "\n",
    "    # #ROI feature vector size (2*#roi,3000)\n",
    "    ROI_feature = self.ROI_head(roi)\n",
    "\n",
    "    # # Classification label \n",
    "    result_labels_probabilities = self.classficiation_label(ROI_feature)\n",
    "    # print(result_labels_probabilities.shape)\n",
    "    # print(result_labels_probabilities[0])\n",
    "\n",
    "    # # BBOX Regresor\n",
    "    # # Let bk = (bkx,bky,bkh,bkw) be the output for class k (k = 1,2) from the FC layer just before the bbox regressor in Figure 2\n",
    "    bk = self.fc_before_regressor(ROI_feature)\n",
    "    \n",
    "\n",
    "    d_bk = self.regressor(ROI_feature)\n",
    "    \n",
    "    # print(bk.shape)\n",
    "    # print(d_bk.shape)\n",
    "\n",
    "\n",
    "    # (x,y,w,h,x,y,w,h) first 4 is coordinate for class 1, second 4 is coordinate for class 2\n",
    "    bk_wh_1 = bk[:,2:4] \n",
    "    # bk_wh_2 = bk[:,6:8]\n",
    "\n",
    "    # bk_w = torch.cat([bk_w_1,bk_w_2], 1)\n",
    "    # bk_h = torch.cat([bk_h_1,bk_h_2], 1)\n",
    "    bk_w_h =  torch.cat([bk_wh_1,bk_wh_1], 1)\n",
    "\n",
    "    b_hat = bk_w_h*d_bk\n",
    "    # print(b_hat.shape)\n",
    "\n",
    "    b_hat[:,0:2] = b_hat[:,0:2] + bk[:,0:2]\n",
    "    # b_hat[:,4:6] = b_hat[:,4:6] + bk[:,4:6]\n",
    "\n",
    "    \n",
    "    # result_labels_probabilities = SIZE(BATCH_SIZE*ROI_PER_IMAGE, 3) B_HAT = SIZE(BATCH_SIZE*ROI_PER_IMAGE, 2*4)\n",
    "    return result_labels_probabilities, b_hat\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjar2NxMDrjx"
   },
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDqw0pvf5kHg"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        # David Add\n",
    "        self.fileName = \"checkpoint.tar\"\n",
    "\n",
    "    def __call__(self, val_loss, model, epoch, save_path):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, epoch, save_path)\n",
    "        elif score <= self.best_score:\n",
    "            self.counter += 1\n",
    "            print(\n",
    "                f'EarlyStopping counter: {self.counter} out of {self.patience}'\n",
    "            )\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, epoch, save_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, epoch, save_path):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...'\n",
    "            )\n",
    "        # David Add\n",
    "        if os.path.exists(os.path.join(save_path, self.fileName)):\n",
    "          !rm os.path.join(save_path, self.fileName)\n",
    "        torch.save(model, os.path.join(save_path, self.fileName))\n",
    "        self.val_loss_min = val_loss\n",
    "        #torch.save(\n",
    "        #    model, save_path + \"/\" +\n",
    "        #    \"checkpoint_{}_{:.6f}.pth.tar\".format(epoch, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OphbjZKK4wPt"
   },
   "outputs": [],
   "source": [
    "def train(model, weight_decay, earlystopping_patience, run_dir, save_dir, new_roi_proposal=False): #run dir is for tensorboard save_dir is for saving model\n",
    "\n",
    "    save_dir = save_dir\n",
    "    run_dir = run_dir \n",
    "    if not os.path.isdir(run_dir):\n",
    "        os.makedirs(run_dir)\n",
    "    tb = SummaryWriter(run_dir)\n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=earlystopping_patience, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "    if os.path.exists(os.path.join(save_dir, 'checkpoint.pth.tar')):\n",
    "        # load existing model\n",
    "        print('==> loading existing model')\n",
    "        model_info = torch.load(os.path.join(save_dir, 'checkpoin.pth.tar'))\n",
    "        model.load_state_dict(model_info['state_dict'])\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        optimizer.load_state_dict(model_info['optimizer'])\n",
    "        cur_epoch = model_info['epoch'] + 1\n",
    "    else:\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        cur_epoch = 0\n",
    "\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(),lr=LR)\n",
    "    pla_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                      factor=0.5,\n",
    "                                                      patience=4,\n",
    "                                                      verbose=True)\n",
    "    \n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = []\n",
    "\n",
    "    for epoch in range(cur_epoch, EPOCHS + 1):\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "\n",
    "        current_epoch_loss = []\n",
    "\n",
    "        for data in train_dataloader:\n",
    "  \n",
    "          imgs, boxes, turbs, rois = data\n",
    "\n",
    "          imgs_tensor = torch.zeros([len(imgs),3,840,840])\n",
    "\n",
    "\n",
    "          for i in range(len(imgs)):\n",
    "            imgs_tensor[i] = imgs[i]\n",
    "\n",
    "          # roi_index_list = [[1,2,3,4,5,6,7,8,9,10], [11,12,13,14,22,23,88,87,42,44]]\n",
    "          roi_index_list = mini_batch_sampling(rois, model.rois_per_image, 0.5, new_roi_proposal) \n",
    "\n",
    "          gt_roi_labels = torch.zeros([2*model.rois_per_image]) #20 = batch*rois_per_image\n",
    "          gt_roi_coord = torch.zeros([2*model.rois_per_image,4])\n",
    "\n",
    "          roi_list = torch.zeros([2*model.rois_per_image,5], dtype=torch.float32) \n",
    "          for i in range(len(roi_index_list)):\n",
    "            # roi_per_image = torch.zeros([10,4], dtype=torch.float32) \n",
    "            for j in range(len(roi_index_list[i])):\n",
    "              try:\n",
    "                roi_list[i*10+j,:] = torch.tensor(np.insert(rois[i][roi_index_list[i][j]][0], 0, i))\n",
    "                gt_roi_labels[i*10+j] = torch.tensor(rois[i][roi_index_list[i][j]][1][\"gt_box_class\"])\n",
    "                gt_roi_coord[i*10+j] = torch.tensor(rois[i][roi_index_list[i][j]][1][\"gt_box_coord_xywh\"])\n",
    "              except:\n",
    "                print(\"i: \",i)\n",
    "                print(\"j: \",j)\n",
    "\n",
    "          \n",
    "          # print(gt_roi_coord)\n",
    "          # print(roi_list\n",
    "          # print(gt_roi_coord)\n",
    "\n",
    "          imgs_tensor = imgs_tensor.cuda()\n",
    "          roi_list = roi_list.cuda()\n",
    "          gt_roi_labels = gt_roi_labels.cuda()\n",
    "          gt_roi_coord = gt_roi_coord.cuda()\n",
    "\n",
    "                \n",
    "          optimizer.zero_grad()\n",
    "          model.train()\n",
    "          result_class_score, result_coord = model(images_data = imgs_tensor, roi_list= roi_list)\n",
    "\n",
    "          # # print(result_coord.shape)\n",
    "\n",
    "          classfication_loss = nn.CrossEntropyLoss()(result_class_score, gt_roi_labels.long())\n",
    "\n",
    "\n",
    "          t_xy = gt_roi_coord-result_coord\n",
    "          t_xy_diff_with_gt = t_xy[:,[0,1]]\n",
    "\n",
    "          p_wh = result_coord[:,[2,3]]\n",
    "          t_xy = torch.div(t_xy_diff_with_gt, p_wh)\n",
    "\n",
    "\n",
    "          gt_wh = gt_roi_coord[:,[2,3]]\n",
    "          t_wh = torch.div(gt_wh,p_wh)\n",
    "          # t_wh_log = torch.log(t_wh)\n",
    "          # print(\"t_wh_log: \",t_wh_log[0])\n",
    "\n",
    "          t_xywh = torch.cat([t_xy,t_wh],1)\n",
    "\n",
    "\n",
    "\n",
    "          loc_loss = fast_rcnn_loc_loss(result_coord, gt_roi_coord, gt_roi_labels, 1)\n",
    "\n",
    "          total_loss = classfication_loss+loc_loss\n",
    "\n",
    "          total_loss.backward()\n",
    "          torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=10.0)\n",
    "          optimizer.step()\n",
    "          \n",
    "          loss_avg = total_loss.item()/BATCH_SIZE\n",
    "          current_epoch_loss.append(loss_avg)\n",
    "          train_losses.append(loss_avg)\n",
    "\n",
    "        loss_avg_epoch = sum(current_epoch_loss) / len(current_epoch_loss)\n",
    "        print('epoch: %i \\t loss_aver: %f'%(epoch, loss_avg_epoch))\n",
    "        \n",
    "\n",
    "        tb.add_scalar('TrainLoss', loss_avg_epoch, epoch)\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        with torch.no_grad():\n",
    "          model.eval()\n",
    "\n",
    "          for data in val_dataloader:\n",
    "    \n",
    "            imgs, boxes, turbs, rois = data\n",
    "\n",
    "            imgs_tensor = torch.zeros([len(imgs),3,840,840])\n",
    "\n",
    "\n",
    "            for i in range(len(imgs)):\n",
    "              imgs_tensor[i] = imgs[i]\n",
    "\n",
    "            ###########################\n",
    "            #mini batch sampling(rois)#\n",
    "            ###########################\n",
    "\n",
    "            roi_index_list = mini_batch_sampling(rois, model.rois_per_image, 0.5, new_roi_proposal) #==> have bug \"index out of range\"\n",
    "\n",
    "            gt_roi_labels = torch.zeros([2*model.rois_per_image]) #20 = batch*rois_per_image\n",
    "            gt_roi_coord = torch.zeros([2*model.rois_per_image,4])\n",
    "\n",
    "            roi_list = torch.zeros([2*model.rois_per_image,5], dtype=torch.float32) \n",
    "            for i in range(len(roi_index_list)):\n",
    "              # roi_per_image = torch.zeros([10,4], dtype=torch.float32) \n",
    "              for j in range(len(roi_index_list[i])):\n",
    "                try:\n",
    "                  roi_list[i*10+j,:] = torch.tensor(np.insert(rois[i][roi_index_list[i][j]][0], 0, i))\n",
    "                  gt_roi_labels[i*10+j] = torch.tensor(rois[i][roi_index_list[i][j]][1][\"gt_box_class\"])\n",
    "                  gt_roi_coord[i*10+j] = torch.tensor(rois[i][roi_index_list[i][j]][1][\"gt_box_coord_xywh\"])\n",
    "                except:\n",
    "                  print(\"i: \",i)\n",
    "                  print(\"j: \",j)\n",
    "\n",
    "            imgs_tensor = imgs_tensor.cuda()\n",
    "            roi_list = roi_list.cuda()\n",
    "            gt_roi_labels = gt_roi_labels.cuda()\n",
    "            gt_roi_coord = gt_roi_coord.cuda()\n",
    "\n",
    "    \n",
    "            result_class_score, result_coord = model(images_data = imgs_tensor, roi_list= roi_list)\n",
    "\n",
    "            # # print(result_coord.shape)\n",
    "\n",
    "            classfication_loss = nn.CrossEntropyLoss()(result_class_score, gt_roi_labels.long())\n",
    "\n",
    "\n",
    "            t_xy = gt_roi_coord-result_coord\n",
    "            t_xy_diff_with_gt = t_xy[:,[0,1]]\n",
    "\n",
    "            p_wh = result_coord[:,[2,3]]\n",
    "            t_xy = torch.div(t_xy_diff_with_gt, p_wh)\n",
    "\n",
    "\n",
    "            gt_wh = gt_roi_coord[:,[2,3]]\n",
    "            t_wh = torch.div(gt_wh,p_wh)\n",
    "\n",
    "            t_xywh = torch.cat([t_xy,t_wh],1)\n",
    "\n",
    "\n",
    "\n",
    "            loc_loss = fast_rcnn_loc_loss(result_coord, gt_roi_coord, gt_roi_labels, 1)\n",
    "\n",
    "            total_loss = classfication_loss+loc_loss\n",
    "\n",
    "            \n",
    "            loss_avg = total_loss.item()/BATCH_SIZE\n",
    "\n",
    "            valid_losses.append(loss_avg)\n",
    "\n",
    "          print('epoch: %i \\t valid_loss_aver: %f'%(epoch, loss_avg))\n",
    "\n",
    "        tb.add_scalar('ValidLoss', loss_avg, epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        # print training/validation statistics\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        epoch_len = len(str(EPOCHS))\n",
    "\n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{EPOCHS:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.6f} ' +\n",
    "                     f'valid_loss: {valid_loss:.6f}')\n",
    "\n",
    "        #print(print_msg)\n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        pla_lr_scheduler.step(valid_loss)  # lr_scheduler\n",
    "        model_dict = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        early_stopping(valid_loss.item(), model_dict, epoch, save_dir)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6DGcZsUrLQ2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlRyZZpDR5rE"
   },
   "source": [
    "## Testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2a2e6nsLR9Da"
   },
   "outputs": [],
   "source": [
    "def test(model, weight_decay, model_address, new_roi_proposal=False):\n",
    "\n",
    "    model = model\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    if os.path.exists(model_address):\n",
    "      # load existing model\n",
    "      print('==> loading existing model')\n",
    "      model_info = torch.load(model_address)\n",
    "      # model_info = torch.load(os.path.join(save_dir, model_file))\n",
    "      model.load_state_dict(model_info['state_dict'])\n",
    "      optimizer = torch.optim.SGD(model.parameters())\n",
    "      optimizer.load_state_dict(model_info['optimizer'])\n",
    "\n",
    "      optimizer = optim.SGD(model.parameters(), lr=LR,weight_decay=weight_decay)\n",
    "\n",
    "      # to track the validation loss as the model trains\n",
    "      valid_losses = []\n",
    "\n",
    "      with torch.no_grad():\n",
    "          model.eval()\n",
    "\n",
    "          for data in test_dataloader:\n",
    "    \n",
    "            imgs, boxes, turbs, rois = data\n",
    "\n",
    "            imgs_tensor = torch.zeros([len(imgs),3,840,840])\n",
    "\n",
    "\n",
    "            for i in range(len(imgs)):\n",
    "              imgs_tensor[i] = imgs[i]\n",
    "\n",
    "            ###########################\n",
    "            #mini batch sampling(rois)#\n",
    "            ###########################\n",
    "            #roi_index_list = [[1,2,3,4,5,6,7,8,9,10], [11,12,13,14,22,23,88,87,42,44]]\n",
    "            roi_index_list = mini_batch_sampling(rois,model.rois_per_image, 0.5, new_roi_proposal) #==> have bug \"index out of range\"\n",
    "\n",
    "            gt_roi_labels = torch.zeros([2*model.rois_per_image]) #20 = batch*rois_per_image\n",
    "            gt_roi_coord = torch.zeros([2*model.rois_per_image,4])\n",
    "            gt_roi_coord_xy = torch.zeros([2*model.rois_per_image,4])\n",
    "\n",
    "            roi_list = torch.zeros([2*model.rois_per_image,5], dtype=torch.float32) \n",
    "            for i in range(len(roi_index_list)):\n",
    "              for j in range(len(roi_index_list[i])):\n",
    "                try:\n",
    "                  roi_list[i*10+j,:] = torch.tensor(np.insert(rois[i][roi_index_list[i][j]][0], 0, i))\n",
    "                  gt_roi_labels[i*10+j] = torch.tensor(rois[i][roi_index_list[i][j]][1][\"gt_box_class\"])\n",
    "                  gt_roi_coord[i*10+j] = torch.tensor(rois[i][roi_index_list[i][j]][1][\"roi_xywh\"])\n",
    "                  gt_roi_coord_xy[i*10+j] = torch.tensor(rois[i][roi_index_list[i][j]][1][\"roi\"])\n",
    "                except:\n",
    "                  print(\"i: \",i)\n",
    "                  print(\"j: \",j)\n",
    "\n",
    "            imgs_tensor = imgs_tensor.cuda()\n",
    "            roi_list = roi_list.cuda()\n",
    "            gt_roi_labels = gt_roi_labels.cuda()\n",
    "            gt_roi_coord = gt_roi_coord.cuda()\n",
    "\n",
    "    \n",
    "            result_class_score, result_coord = model(images_data = imgs_tensor, roi_list= roi_list)\n",
    "\n",
    "            # # print(result_coord.shape)\n",
    "\n",
    "            classfication_loss = nn.CrossEntropyLoss()(result_class_score, gt_roi_labels.long())\n",
    "\n",
    "\n",
    "            t_xy = gt_roi_coord-result_coord\n",
    "            t_xy_diff_with_gt = t_xy[:,[0,1]]\n",
    "\n",
    "            p_wh = result_coord[:,[2,3]]\n",
    "            t_xy = torch.div(t_xy_diff_with_gt, p_wh)\n",
    "\n",
    "\n",
    "            gt_wh = gt_roi_coord[:,[2,3]]\n",
    "            t_wh = torch.div(gt_wh,p_wh)\n",
    "\n",
    "            t_xywh = torch.cat([t_xy,t_wh],1)\n",
    "\n",
    "\n",
    "\n",
    "            loc_loss = fast_rcnn_loc_loss(result_coord, gt_roi_coord, gt_roi_labels, 1)\n",
    "\n",
    "            total_loss = classfication_loss+loc_loss\n",
    "\n",
    "            \n",
    "            loss_avg = total_loss.item()/BATCH_SIZE\n",
    "\n",
    "            valid_losses.append(loss_avg)\n",
    "\n",
    "            #Calculaing average IoU of this images'roi\n",
    "            for roi_index, roi in result_coord:\n",
    "              roi_xy = np.array([roi[0],roi[1],roi[0]+roi[2],roi[2]-roi[0]])  \n",
    "              iou_score = compute_IoU(roi,gt_roi_coord_xy[roi_index])\n",
    "\n",
    "            iou_score = compute_IoU(, gt_box)\n",
    "\n",
    "      torch.cuda.empty_cache()\n",
    "      valid_loss = np.average(valid_losses)\n",
    "      print('loss_aver: %f'%(valid_loss))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "      print(\"Model not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0M4n6rhf0kM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1-ogcozDxfF"
   },
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NznfX1lnFg1P"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2 #DoN'T CHANGE NO ENOUGH GPU \n",
    "EPOCHS = 100\n",
    "LR = 0.001\n",
    "WEIGHT_DECAY = 0.000001\n",
    "EARLY_STOPPING_PATIENCE = 6 #EPOCHS\n",
    "NEW_ROI_PROPOSAL = False\n",
    "PRE_TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZ6BLwiaHXDl"
   },
   "outputs": [],
   "source": [
    "model = Fast_R_cnn(roi_size=13,scaling_factor=float(51/840),rois_per_image=20,pretrained=PRE_TRAIN)\n",
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgnTHYQJsmaf"
   },
   "outputs": [],
   "source": [
    "run_dir = '/content/data/run/Sean_train_12_21/' \n",
    "save_dir = '/content/data/model/Sean_train_12_21/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG_PEtOjs3wp"
   },
   "source": [
    "### HYPER PARAMETERS (CAN BE CHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h43ywgUota5j",
    "outputId": "4cb35878-a074-45f9-f54d-1979a92a2a58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t loss_aver: 371.797291\n",
      "epoch: 0 \t valid_loss_aver: 258.522339\n",
      "Validation loss decreased (inf --> 381.086608).  Saving model ...\n",
      "epoch: 1 \t loss_aver: 371.784008\n",
      "epoch: 1 \t valid_loss_aver: 258.513428\n",
      "Validation loss decreased (381.086608 --> 381.073450).  Saving model ...\n",
      "epoch: 2 \t loss_aver: 371.770705\n",
      "epoch: 2 \t valid_loss_aver: 258.504425\n",
      "Validation loss decreased (381.073450 --> 381.060250).  Saving model ...\n",
      "epoch: 3 \t loss_aver: 371.757363\n",
      "epoch: 3 \t valid_loss_aver: 258.495453\n",
      "Validation loss decreased (381.060250 --> 381.047010).  Saving model ...\n",
      "epoch: 4 \t loss_aver: 371.743966\n",
      "epoch: 4 \t valid_loss_aver: 258.486389\n",
      "Validation loss decreased (381.047010 --> 381.033714).  Saving model ...\n",
      "epoch: 5 \t loss_aver: 371.730511\n",
      "epoch: 5 \t valid_loss_aver: 258.477356\n",
      "Validation loss decreased (381.033714 --> 381.020351).  Saving model ...\n",
      "epoch: 6 \t loss_aver: 371.716969\n",
      "epoch: 6 \t valid_loss_aver: 258.468170\n",
      "Validation loss decreased (381.020351 --> 381.006895).  Saving model ...\n",
      "epoch: 7 \t loss_aver: 371.703334\n",
      "epoch: 7 \t valid_loss_aver: 258.458893\n",
      "Validation loss decreased (381.006895 --> 380.993325).  Saving model ...\n",
      "epoch: 8 \t loss_aver: 371.689553\n",
      "epoch: 8 \t valid_loss_aver: 258.449585\n",
      "Validation loss decreased (380.993325 --> 380.979613).  Saving model ...\n",
      "epoch: 9 \t loss_aver: 371.675613\n",
      "epoch: 9 \t valid_loss_aver: 258.440094\n",
      "Validation loss decreased (380.979613 --> 380.965711).  Saving model ...\n",
      "epoch: 10 \t loss_aver: 371.661445\n",
      "epoch: 10 \t valid_loss_aver: 258.430389\n",
      "Validation loss decreased (380.965711 --> 380.951557).  Saving model ...\n",
      "epoch: 11 \t loss_aver: 371.646971\n",
      "epoch: 11 \t valid_loss_aver: 258.420471\n",
      "Validation loss decreased (380.951557 --> 380.937055).  Saving model ...\n",
      "epoch: 12 \t loss_aver: 371.632077\n",
      "epoch: 12 \t valid_loss_aver: 258.410126\n",
      "Validation loss decreased (380.937055 --> 380.922062).  Saving model ...\n",
      "epoch: 13 \t loss_aver: 371.616554\n",
      "epoch: 13 \t valid_loss_aver: 258.399261\n",
      "Validation loss decreased (380.922062 --> 380.906333).  Saving model ...\n",
      "epoch: 14 \t loss_aver: 371.600093\n",
      "epoch: 14 \t valid_loss_aver: 258.387451\n",
      "Validation loss decreased (380.906333 --> 380.889414).  Saving model ...\n",
      "epoch: 15 \t loss_aver: 371.582020\n",
      "epoch: 15 \t valid_loss_aver: 258.374115\n",
      "Validation loss decreased (380.889414 --> 380.870425).  Saving model ...\n",
      "epoch: 16 \t loss_aver: 371.560963\n",
      "epoch: 16 \t valid_loss_aver: 258.357635\n",
      "Validation loss decreased (380.870425 --> 380.847375).  Saving model ...\n",
      "epoch: 17 \t loss_aver: 371.533475\n",
      "epoch: 17 \t valid_loss_aver: 258.333832\n",
      "Validation loss decreased (380.847375 --> 380.814766).  Saving model ...\n",
      "epoch: 18 \t loss_aver: 371.487767\n",
      "epoch: 18 \t valid_loss_aver: 258.285034\n",
      "Validation loss decreased (380.814766 --> 380.749870).  Saving model ...\n",
      "epoch: 19 \t loss_aver: 371.343400\n",
      "epoch: 19 \t valid_loss_aver: 258.028107\n",
      "Validation loss decreased (380.749870 --> 380.417198).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "train(model=model, weight_decay=WEIGHT_DECAY, earlystopping_patience=EARLY_STOPPING_PATIENCE, run_dir=run_dir, save_dir=save_dir, new_roi_proposal=NEW_ROI_PROPOSAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDtMsGNmGkqe"
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsTjsayNHQGn"
   },
   "outputs": [],
   "source": [
    "test_model = Fast_R_cnn(roi_size=13,scaling_factor=float(51/840),rois_per_image=20,pretrained=PRE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFo268ouH3fy"
   },
   "outputs": [],
   "source": [
    "test_model_address = '/content/data/model/Sean_train_12_21/checkpoint_9_380.965711.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko_mWXr7z4-e"
   },
   "outputs": [],
   "source": [
    "test(model=test_model, weight_decay=WEIGHT_DECAY, test_model_address=test_model_address,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqbDI344z5hr"
   },
   "source": [
    "## Display predicited result incomparison to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dJCWnIT0AgA"
   },
   "outputs": [],
   "source": [
    "def imshow(img, gt_box, turb_type,pred_box=None):\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    def draw_box(box, turb_type):\n",
    "        x, y, w, h = box\n",
    "        if x == 0:\n",
    "            x = 1\n",
    "        if y == 0:\n",
    "            y = 1\n",
    "        if turb_type==2:\n",
    "          color='red'\n",
    "        else:\n",
    "          color='green'\n",
    "        plt.gca().add_patch(\n",
    "            plt.Rectangle((x, y), w-x, h-y,\n",
    "                          fill=False, edgecolor=color, linewidth=2, alpha=0.5)\n",
    "        )\n",
    "    for i in range(len(box)):\n",
    "      draw_box(box[i],turb_type[i])\n",
    "    if pred_box is not None:\n",
    "        draw_box(pred_box, 'blue')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwQT52HN0i0s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkqrDJmhu5zk"
   },
   "source": [
    "## 8787878787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRKs6d03u-jO",
    "outputId": "12da1080-2b43-4dbe-e126-141d8a139513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0\n",
      "j:  40\n",
      "roi_index_list:  2 181\n",
      "i:  0\n",
      "j:  40\n",
      "roi_index_list:  2 190\n",
      "i:  1\n",
      "j:  30\n",
      "roi_index_list:  2 182\n",
      "i:  0\n",
      "j:  40\n",
      "roi_index_list:  2 189\n",
      "i:  0\n",
      "j:  40\n",
      "roi_index_list:  2 190\n",
      "i:  1\n",
      "j:  30\n",
      "roi_index_list:  2 183\n",
      "i:  0\n",
      "j:  40\n",
      "roi_index_list:  2 175\n",
      "i:  0\n",
      "j:  40\n",
      "roi_index_list:  2 184\n",
      "i:  1\n",
      "j:  30\n",
      "roi_index_list:  2 179\n",
      "i:  0\n",
      "j:  40\n",
      "roi_index_list:  2 190\n",
      "i:  0\n",
      "j:  40\n",
      "roi_index_list:  2 184\n",
      "i:  0\n",
      "j:  40\n",
      "roi_index_list:  2 185\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataloader:\n",
    "  imgs, boxes, turbs, rois = data\n",
    "\n",
    "  imgs_tensor = torch.zeros([len(imgs),3,840,840])\n",
    "\n",
    "  for i in range(len(imgs)):\n",
    "    imgs_tensor[i] = imgs[i]\n",
    "\n",
    "  # roi_index_list = [[1,2,3,4,5,6,7,8,9,10], [11,12,13,14,22,23,88,87,42,44]]\n",
    "  roi_index_list = mini_batch_sampling(rois, model.rois_per_image, 0.5)\n",
    "\n",
    "  gt_roi_labels = torch.zeros([2*model.rois_per_image]) #= batch*rois_per_image\n",
    "  gt_roi_coord = torch.zeros([2*model.rois_per_image,4])\n",
    "\n",
    "  roi_list = torch.zeros([2*model.rois_per_image,5], dtype=torch.float32) \n",
    "  for i in range(len(roi_index_list)):\n",
    "    # roi_per_image = torch.zeros([10,4], dtype=torch.float32) \n",
    "    for j in range(len(roi_index_list[i])):\n",
    "      try:\n",
    "        roi_list[i*10+j,:] = torch.tensor(np.insert(rois[i][roi_index_list[i][j]][0], 0, i))\n",
    "        gt_roi_labels[i*10+j] = torch.tensor(rois[i][roi_index_list[i][j]][1][\"gt_box_class\"])\n",
    "        gt_roi_coord[i*10+j] = torch.tensor(rois[i][roi_index_list[i][j]][1][\"gt_box_coord_xywh\"])\n",
    "      except:\n",
    "        print(\"i: \",i)\n",
    "        print(\"j: \",j)\n",
    "        print(\"roi_index_list: \", len(roi_index_list), len(roi_index_list[i]))\n",
    "        break\n",
    "  # print(roi_list.shape)\n",
    "  # print(gt_roi_coord)\n",
    "  # print(roi_list\n",
    "  # print(gt_roi_coord)\n",
    "\n",
    "  # imgs_tensor = imgs_tensor.cuda()\n",
    "  # roi_list = roi_list.cuda()\n",
    "  # gt_roi_labels = gt_roi_labels.cuda()\n",
    "  # gt_roi_coord = gt_roi_coord.cuda()\n",
    "\n",
    "  # optimizer.zero_grad()\n",
    "  # result_class_score, result_coord = model(images_data = imgs_tensor, roi_list= roi_list)\n",
    "\n",
    "  # # # print(result_coord.shape)\n",
    "\n",
    "  # classfication_loss = nn.CrossEntropyLoss()(result_class_score, gt_roi_labels.long())\n",
    "\n",
    "\n",
    "  # t_xy = gt_roi_coord-result_coord\n",
    "  # t_xy_diff_with_gt = t_xy[:,[0,1]]\n",
    "\n",
    "  # p_wh = result_coord[:,[2,3]]\n",
    "  # t_xy = torch.div(t_xy_diff_with_gt, p_wh)\n",
    "\n",
    "\n",
    "  # gt_wh = gt_roi_coord[:,[2,3]]\n",
    "  # t_wh = torch.div(gt_wh,p_wh)\n",
    "  # # t_wh_log = torch.log(t_wh)\n",
    "  # # print(\"t_wh_log: \",t_wh_log[0])\n",
    "\n",
    "  # t_xywh = torch.cat([t_xy,t_wh],1)\n",
    "\n",
    "\n",
    "\n",
    "  # loc_loss = fast_rcnn_loc_loss(result_coord, gt_roi_coord, gt_roi_labels, 1)\n",
    "\n",
    "  # total_loss = classfication_loss+loc_loss\n",
    "\n",
    "  # total_loss.backward()\n",
    "  # optimizer.step()\n",
    "  # print(total_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnFpGlKKCovB"
   },
   "source": [
    "##Data visulize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXzg-KA7G2xa"
   },
   "outputs": [],
   "source": [
    "def imshow(img, gt_box, turb_type,pred_box=None):\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    def draw_box(box, turb_type):\n",
    "        x1, y1, x2, y2 = box\n",
    "        if x1 == 0:\n",
    "            x1 = 1\n",
    "        if y1 == 0:\n",
    "            y1 = 1\n",
    "        if turb_type==2:\n",
    "          color='red'\n",
    "        else:\n",
    "          color='green'\n",
    "        plt.gca().add_patch(\n",
    "            plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                          fill=False, edgecolor=color, linewidth=2, alpha=0.5)\n",
    "        )\n",
    "    for i in range(len(box)):\n",
    "      draw_box(box[i],turb_type[i])\n",
    "    if pred_box is not None:\n",
    "        draw_box(pred_box, 'blue')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "eIA-o0-hCsw4",
    "outputId": "2f9351e2-8375-4a68-def7-3907edf6b641"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#transform1=transforms.Compose([transforms.ColorJitter(hue=0.1)])\n",
    "dataset=test_dataloader.dataset\n",
    "im, box, turb, rois = dataset[0]\n",
    "\n",
    "inp = im.numpy().transpose((1, 2, 0))\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "inp = std * inp + mean\n",
    "imshow(inp, box,turb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBtAFg9WYMVf",
    "outputId": "008b8b26-0e79-4771-90d5-ebe1fb4e493b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[316.0, 372.0, 474.0, 475.0],\n",
       " [135.0, 223.0, 292.0, 307.0],\n",
       " [452.0, 383.0, 576.0, 477.0],\n",
       " [557.0, 405.0, 683.0, 489.0],\n",
       " [494.0, 11.0, 624.0, 72.0],\n",
       " [332.0, 247.0, 515.0, 334.0],\n",
       " [165.0, 332.0, 266.0, 425.0]]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEy0ZGMR6veO",
    "outputId": "2543da16-5fe9-496e-b4a3-994102e44e94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 1, 2, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ff8kEQOzQErq"
   },
   "outputs": [],
   "source": [
    "!rm \"/content/data/temp.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETKyrgcQsNLc"
   },
   "outputs": [],
   "source": [
    "target_fileName = [\"HS_H08_20160313_0330_25.41_122.35.npy\",\n",
    "                   \"HS_H08_20171122_1600_32.56_133.1.npy\",\n",
    "                   \"HS_H08_20180312_1730_27.06_106.49.npy\",\n",
    "                   \"HS_H08_20190105_0430_32.541389_114.077778.npy\"]\n",
    "\n",
    "output = []\n",
    "with open('data/bbox_test.csv') as f:\n",
    "    idx = -1\n",
    "    lass_name = 'none'\n",
    "    for line in f.read().splitlines():\n",
    "        filename, _, _, _, _ = line.split(',')\n",
    "        \n",
    "        if filename == last_name:\n",
    "            continue\n",
    "        else:\n",
    "            idx = idx + 1\n",
    "        \n",
    "        if filename in target_fileName:\n",
    "            output = output + idx\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Fast_R_cnn_with_my_report.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
